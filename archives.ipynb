{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edgar_downloader as ed\n",
    "import edgar_cleaner as ec\n",
    "import ref_data as ref_data\n",
    "import edgar_sentiment_wordcount as esw\n",
    "import edgar_sentiment_analysis_prep as esap\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notes: \n",
    "\n",
    "TMX not found in SEC API\n",
    "\n",
    "Error with prices as a key - TMX\n",
    "\n",
    "added encoding to wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Edgar_EC\\edgar_ec\\edgar_ec\\edgar_sentiment_analysis_prep.py:69: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  new_df['word_sum'] = new_df.sum(axis = 1)                                           # Calculate total number of categorised words from the report\n"
     ]
    }
   ],
   "source": [
    "def full_train_dataset(): # input_min_date = None, input_max_date = None\n",
    "    '''\n",
    "    Creates a csv to specified file path\n",
    "    '''\n",
    "\n",
    "    #needs to create a new temp folder to drop raw files into, process them then delete, and a specified folder argument for the output\n",
    "    #0 handling in output file (in 10 working days of stock market) - min maxes for dates\n",
    "    #\n",
    "\n",
    "    tickers_sp100 = ref_data.get_sp100()\n",
    "    #ed.download_files_10k(‘AAPL’, ‘C:/10k_filings_raw’)\n",
    "    ###ed.full_download(tickers_sp100, r'C:\\Edgar_EC\\Archives\\raw_files', 'gregsmith@kubrickgroup.com', min_date = '2000-01-01') #min_date = input_min_date, max_date = input_max_date,\n",
    "\n",
    "    ###ec.write_clean_html_text_files(r'C:\\Edgar_EC\\Archives\\raw_files', r'C:\\Edgar_EC\\Archives\\refined_files')\n",
    "\n",
    "    #df_returns = rf.get_yahoo_data(input_min_date, input_max_date, tickers_sp100, 'daily')\n",
    "    ###df_returns = ref_data.get_yahoo_data('2000-01-01', '2023-08-01', tickers_sp100) # Need to decide dates as I have to pass a date here\n",
    "    ###df_returns.to_csv(r'C:\\Edgar_EC\\Archives\\intermediates\\stock_returns_daily.csv', index=False)\n",
    "    ###sentiment_dict = ref_data.get_sentiment_word_dict()\n",
    "\n",
    "    ###esw.write_document_sentiments(r'C:\\Edgar_EC\\Archives\\refined_files', r'C:\\Edgar_EC\\Archives\\intermediates\\sentiment_factors.csv')\n",
    "\n",
    "    # Load Data\n",
    "    stock_returns_daily_df = pd.read_csv(r'C:\\Edgar_EC\\Archives\\intermediates\\stock_returns_daily.csv')                         # Load in stock return data\n",
    "    sentiment_factors_df = pd.read_csv(r'C:\\Edgar_EC\\Archives\\intermediates\\sentiment_factors.csv')                             # Load in sentiment word count data\n",
    "    #stock_returns_daily_df = pd.read_csv('C:/EDGAR/example_shares_output2.csv')   \n",
    "    #sentiment_factors_df = pd.read_csv('C:/EDGAR/example_sentiment_analysis.csv')  \n",
    "    \n",
    "    # Processing and Feature Engineering\n",
    "    full_stock_returns_daily_df = stock_returns_prep(stock_returns_daily_df)\n",
    "    full_sentiment_factors_df = esap.sentiment_factors_prep(sentiment_factors_df)\n",
    "    \n",
    "    # Combine Datasets\n",
    "    full_combined_df = pd.merge(full_sentiment_factors_df, full_stock_returns_daily_df, on = ['Date', 'Symbol'], how = 'left')\n",
    "\n",
    "    full_combined_df.to_csv(r'C:\\Edgar_EC\\Archives\\data\\full_dataset.csv', index = False)              # Will need to decide a better place for this\n",
    "\n",
    "def stock_returns_prep(df): \n",
    "    \n",
    "    new_df = df.drop(['High', 'Low'], axis = 1)                       # Remove unnessary columns # sample_stock_returns_daily_df\n",
    "    new_df.rename(columns={\"date\": \"Date\"}, inplace= True)                     # Change date column name for later merge\n",
    "\n",
    "    return new_df\n",
    "\n",
    "full_train_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
