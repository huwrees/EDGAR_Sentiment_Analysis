{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walkthrough of sentiment_analysis_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Imports\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "#stock_returns_daily_df = pd.read_csv('C:/stock_returns_daily.csv')                         # Load in stock return data\n",
    "stock_returns_daily_df = pd.read_csv('C:/EDGAR/example_shares_output2.csv')                 # Load in stock return data\n",
    "#print(stock_returns_daily_df)\n",
    "\n",
    "#sentiment_factors_df = pd.read_csv('C:/sentiment_factors.csv')                             # Load in sentiment word count data\n",
    "sentiment_factors_df = pd.read_csv('C:/EDGAR/example_sentiment_analysis.csv')               # Load in sentiment word count data\n",
    "#print(sentiment_factors_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing?\n",
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_returns_daily\n",
    "def stock_returns_prep(df): \n",
    "    # Do I need to format the dates?\n",
    "    new_df = df.drop(['high', 'low', 'price','Symbol'], axis = 1)                       # Remove unnessary columns # sample_stock_returns_daily_df\n",
    "    new_df.rename(columns={\"date\": \"Date\"}, inplace= True)                              # Change date column name for later merge\n",
    "    # Potentially do not drop symbol so they can later be matched\n",
    "    \n",
    "    # Make in classiication columns? Up, Down (& stagnant)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_factors\n",
    "def sentiment_factors_prep(df):  \n",
    "    # Do I need to format the dates?\n",
    "    new_df = df.drop(['Symbol', 'ReportType'], axis = 1)                                # Remove unnessary columns\n",
    "    new_df.rename(columns={\"FilingDate\": \"Date\"}, inplace= True)                        # Change date column name for later merge\n",
    "    new_df['word_sum'] = new_df.sum(axis = 1)                                           # Calculate total number of categorised words from the report\n",
    "    # Potentially do not drop symbol so they can later be matched\n",
    "    \n",
    "    # Normalise wordcounts as a % of sum of word counts or report word count? \n",
    "    new_df['perc_Negative'] = new_df.apply(lambda row: row['Negative'] / row['word_sum'], axis = 1)\n",
    "    new_df['perc_Positive'] = new_df.apply(lambda row: row['Positive'] / row['word_sum'], axis = 1)\n",
    "    new_df['perc_Uncertainty'] = new_df.apply(lambda row: row['Uncertainty'] / row['word_sum'], axis = 1)\n",
    "    new_df['perc_Litigious'] = new_df.apply(lambda row: row['Litigious'] / row['word_sum'], axis = 1)\n",
    "    new_df['perc_Constraining'] = new_df.apply(lambda row: row['Constraining'] / row['word_sum'], axis = 1)\n",
    "    new_df['perc_Superfluous'] = new_df.apply(lambda row: row['Superfluous'] / row['word_sum'], axis = 1)\n",
    "    new_df['perc_Interesting'] = new_df.apply(lambda row: row['Interesting'] / row['word_sum'], axis = 1)\n",
    "    new_df['perc_Modal'] = new_df.apply(lambda row: row['Modal'] / row['word_sum'], axis = 1)\n",
    "    #S entiment Scores\n",
    "    new_df['sentiment_score'] = new_df.apply(lambda row: round((row['Positive'] - row['Negative']) / (row['Positive'] + row['Negative']), 2), axis = 1)  \n",
    "    # Using Positive and Negative Word Count – With Normalization for Calculating Sentiment Score\n",
    "    new_df['sentiment1'] = new_df.apply(lambda row: round((row['Positive'] - row['Negative']) / row['word_sum'], 2), axis = 1)       # Calculate a Sentiment score using positive & negative word counts \n",
    "    # Using Positive and Negative Word Counts – With Semi Normalization to calculate Sentiment Score\n",
    "    new_df['sentiment2'] = new_df.apply(lambda row: round(row['Positive'] / (row['Negative'] + 1), 2), axis = 1) \n",
    "    # round(df['pos_count'] / (df['neg_count']+1), 2)\n",
    "\n",
    "    # or report word count? \n",
    "    \n",
    "    # Normalise wordcounts over dataset instead of individual reports?\n",
    "    # def min_max(s):\n",
    "    #     new_s = (s - s.min())/(s.max() - s.min())\n",
    "    # return new_s\n",
    "\n",
    "    # df['Positive'] = min_max(df['Positive'])                                               # normalise 'Positive'\n",
    "    # df['Negative'] = min_max(df['Negative'])                                               # normalise 'Negative'\n",
    "    # df['Uncertainty'] = min_max(df['Uncertainty'])                                         # normalise 'Uncertainty'\n",
    "    # df['Litigious'] = min_max(df['Litigious'])                                             # normalise 'Litigious'\n",
    "    # df['Constraining'] = min_max(df['Constraining'])                                       # normalise 'Constraining'\n",
    "    # df['Superfluous'] = min_max(df['Superfluous'])                                         # normalise 'Superfluous'\n",
    "    # df['Interesting'] = min_max(df['Interesting'])                                         # normalise 'Interesting'\n",
    "    # df['Modal'] = min_max(df['Modal'])                                                     # normalise 'Modal'\n",
    "    \n",
    "    # Drop unnessary columns, raw word category counts\n",
    "    new_df.drop(['Negative', 'Positive', 'Uncertainty', 'Litigious', 'Constraining', 'Superfluous', 'Interesting', 'Modal'], axis = 1, inplace = True)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View resulting DataFrames\n",
    "\n",
    "sample_stock_returns_daily_df = stock_returns_prep(stock_returns_daily_df)\n",
    "sample_sentiment_factors_df = sentiment_factors_prep(sentiment_factors_df)\n",
    "#print(sample_stock_returns_daily_df)\n",
    "#print(sample_stock_returns_daily_df.columns)\n",
    "print(sample_sentiment_factors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining dataframes using merge\n",
    "# merge on date and ticker symbol?\n",
    "combined_df = pd.merge(sample_stock_returns_daily_df, sample_sentiment_factors_df, on = 'Date', how = 'left') # on = ['Date', 'ticker'] for larger set...\n",
    "\n",
    "print(combined_df)\n",
    "print(combined_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential Features & Targets\n",
    "all_features = ['Negative', 'Positive', 'Uncertainty', 'Litigious', 'Constraining', 'Superfluous', 'Interesting', 'Modal',\n",
    "                'perc_Negative', 'perc_Positive', 'perc_Uncertainty', 'perc_Litigious', 'perc_Constraining', 'perc_Superfluous', 'perc_Interesting', 'perc_Modal',\n",
    "                 'sentiment_score', 'sentiment1','sentiment2']\n",
    "all_sentiment_features = ['Negative', 'Positive', 'Uncertainty', 'Litigious', 'Constraining', 'Superfluous', 'Interesting', 'Modal']\n",
    "neg_pos_features = ['Negative', 'Positive']\n",
    "neg_feature = ['Negative']\n",
    "\n",
    "selected_features = all_sentiment_features\n",
    "target = ['1daily return'] # ['2daily return'], ['3daily return'], ['5daily return'], ['10daily return'], ['volume']\n",
    "\n",
    "# X_train = df_train[selected_features]                     # NB -- we use upper case 'X' because it is a matrix (math term for df)\n",
    "# y_train = df_train[target]                                # NB -- we use lower case 'y' because it is a vactor (math term for series)\n",
    "\n",
    "# X_test = df_test[selected_features]                       # NB -- we use upper case 'X' because it is a matrix (math term for df)\n",
    "# y_test = df_test[target]                                  # NB -- we use lower case 'y' because it is a vactor (math term for series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that takes \n",
    "# yahoo data\n",
    "# sentiment word counts \n",
    "\n",
    "# and returns merged dataframe"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
