{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "127bfe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import edgar_downloader as ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db3294ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ed.download_files_10k('aapl', r'C:\\Edgar_EC\\test_output', 'gregsmith@kubickgroup.com', min_date='2010-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c884fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import edgar_cleaner as ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "554a9c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "ec.write_clean_html_text_files(r'C:\\Edgar_EC\\test_output', r'C:\\Edgar_EC\\test_output_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aea9e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ref_data as ref_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c247e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import edgar_sentiment_wordcount as esw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf9b9d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "esw.write_document_sentiments(r'C:\\Edgar_EC\\test_output_2', r'C:\\Edgar_EC\\sentiment_factors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7f16cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\ref_data.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(ticker_data, sort=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>volume</th>\n",
       "      <th>1daily_return</th>\n",
       "      <th>2daily_return</th>\n",
       "      <th>3daily_return</th>\n",
       "      <th>5daily_return</th>\n",
       "      <th>10daily_return</th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>7.660714</td>\n",
       "      <td>7.585000</td>\n",
       "      <td>7.643214</td>\n",
       "      <td>493729600</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>-0.014205</td>\n",
       "      <td>-0.016027</td>\n",
       "      <td>-0.018223</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>7.699643</td>\n",
       "      <td>7.616071</td>\n",
       "      <td>7.656429</td>\n",
       "      <td>601904800</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.017726</td>\n",
       "      <td>-0.011195</td>\n",
       "      <td>-0.031066</td>\n",
       "      <td>-0.012361</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>7.686786</td>\n",
       "      <td>7.526786</td>\n",
       "      <td>7.534643</td>\n",
       "      <td>552160000</td>\n",
       "      <td>-0.001849</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>-0.004076</td>\n",
       "      <td>-0.001517</td>\n",
       "      <td>-0.013746</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>7.466071</td>\n",
       "      <td>7.520714</td>\n",
       "      <td>477131200</td>\n",
       "      <td>0.006648</td>\n",
       "      <td>-0.002232</td>\n",
       "      <td>-0.013582</td>\n",
       "      <td>-0.005461</td>\n",
       "      <td>-0.060927</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>7.466429</td>\n",
       "      <td>7.570714</td>\n",
       "      <td>447610800</td>\n",
       "      <td>-0.008821</td>\n",
       "      <td>-0.020096</td>\n",
       "      <td>-0.006274</td>\n",
       "      <td>-0.028540</td>\n",
       "      <td>-0.042032</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>135.199997</td>\n",
       "      <td>131.320007</td>\n",
       "      <td>132.369995</td>\n",
       "      <td>79592600</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>0.023268</td>\n",
       "      <td>-0.001058</td>\n",
       "      <td>-0.017678</td>\n",
       "      <td>-0.045403</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>2022-12-20</td>\n",
       "      <td>133.250000</td>\n",
       "      <td>129.889999</td>\n",
       "      <td>132.300003</td>\n",
       "      <td>77432800</td>\n",
       "      <td>0.023809</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>-0.003326</td>\n",
       "      <td>-0.047317</td>\n",
       "      <td>-0.055027</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>136.809998</td>\n",
       "      <td>132.750000</td>\n",
       "      <td>135.449997</td>\n",
       "      <td>85928000</td>\n",
       "      <td>-0.023773</td>\n",
       "      <td>-0.026504</td>\n",
       "      <td>-0.040015</td>\n",
       "      <td>-0.043116</td>\n",
       "      <td>-0.043042</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>134.559998</td>\n",
       "      <td>130.300003</td>\n",
       "      <td>132.229996</td>\n",
       "      <td>77852100</td>\n",
       "      <td>-0.002798</td>\n",
       "      <td>-0.016638</td>\n",
       "      <td>-0.046812</td>\n",
       "      <td>-0.017394</td>\n",
       "      <td>-0.015730</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>132.419998</td>\n",
       "      <td>129.639999</td>\n",
       "      <td>131.860001</td>\n",
       "      <td>63814900</td>\n",
       "      <td>-0.013878</td>\n",
       "      <td>-0.044138</td>\n",
       "      <td>-0.017064</td>\n",
       "      <td>-0.051494</td>\n",
       "      <td>-0.008570</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3268 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        High         Low       Close     volume  \\\n",
       "0     2010-01-04    7.660714    7.585000    7.643214  493729600   \n",
       "1     2010-01-05    7.699643    7.616071    7.656429  601904800   \n",
       "2     2010-01-06    7.686786    7.526786    7.534643  552160000   \n",
       "3     2010-01-07    7.571429    7.466071    7.520714  477131200   \n",
       "4     2010-01-08    7.571429    7.466429    7.570714  447610800   \n",
       "...          ...         ...         ...         ...        ...   \n",
       "3263  2022-12-19  135.199997  131.320007  132.369995   79592600   \n",
       "3264  2022-12-20  133.250000  129.889999  132.300003   77432800   \n",
       "3265  2022-12-21  136.809998  132.750000  135.449997   85928000   \n",
       "3266  2022-12-22  134.559998  130.300003  132.229996   77852100   \n",
       "3267  2022-12-23  132.419998  129.639999  131.860001   63814900   \n",
       "\n",
       "      1daily_return  2daily_return  3daily_return  5daily_return  \\\n",
       "0          0.001729      -0.014205      -0.016027      -0.018223   \n",
       "1         -0.015906      -0.017726      -0.011195      -0.031066   \n",
       "2         -0.001849       0.004787      -0.004076      -0.001517   \n",
       "3          0.006648      -0.002232      -0.013582      -0.005461   \n",
       "4         -0.008821      -0.020096      -0.006274      -0.028540   \n",
       "...             ...            ...            ...            ...   \n",
       "3263      -0.000529       0.023268      -0.001058      -0.017678   \n",
       "3264       0.023809      -0.000529      -0.003326      -0.047317   \n",
       "3265      -0.023773      -0.026504      -0.040015      -0.043116   \n",
       "3266      -0.002798      -0.016638      -0.046812      -0.017394   \n",
       "3267      -0.013878      -0.044138      -0.017064      -0.051494   \n",
       "\n",
       "      10daily_return Symbol  \n",
       "0           0.004813   AAPL  \n",
       "1          -0.012361   AAPL  \n",
       "2          -0.013746   AAPL  \n",
       "3          -0.060927   AAPL  \n",
       "4          -0.042032   AAPL  \n",
       "...              ...    ...  \n",
       "3263       -0.045403   AAPL  \n",
       "3264       -0.055027   AAPL  \n",
       "3265       -0.043042   AAPL  \n",
       "3266       -0.015730   AAPL  \n",
       "3267       -0.008570   AAPL  \n",
       "\n",
       "[3268 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_data.get_yahoo_data('2010-01-01', '2023-01-01', 'AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "083bbf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import edgar_sentiment_analysis_prep as esap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7eaeda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_yahoo_data() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 34\u001b[0m\n\u001b[0;32m     30\u001b[0m     full_combined_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(full_stock_returns_daily_df, full_sentiment_factors_df, on \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mticker\u001b[39m\u001b[39m'\u001b[39m], how \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     32\u001b[0m     full_combined_df\u001b[39m.\u001b[39mto_csv(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mEDGAR\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mfull_dataset.csv\u001b[39m\u001b[39m'\u001b[39m, index \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)              \u001b[39m# Will need to decide a better place for this\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m full_train_dataset()\n",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m, in \u001b[0;36mfull_train_dataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m ec\u001b[39m.\u001b[39mwrite_clean_html_text_files(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m10k_filings_raw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m10k_filings_clean\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[39m#df_returns = rf.get_yahoo_data(input_min_date, input_max_date, tickers_sp100, 'daily')\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m df_returns \u001b[39m=\u001b[39m ref_data\u001b[39m.\u001b[39;49mget_yahoo_data(\u001b[39m'\u001b[39;49m\u001b[39m2022-01-01\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m2023-08-01\u001b[39;49m\u001b[39m'\u001b[39;49m, tickers_sp100, \u001b[39m'\u001b[39;49m\u001b[39mdaily\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m# Need to decide dates as I have to pass a date here\u001b[39;00m\n\u001b[0;32m     14\u001b[0m df_returns\u001b[39m.\u001b[39mto_csv(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mstock_returns_daily.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m sentiment_dict \u001b[39m=\u001b[39m ref_data\u001b[39m.\u001b[39mget_sentiment_word_dict()\n",
      "\u001b[1;31mTypeError\u001b[0m: get_yahoo_data() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "def full_train_dataset(): # input_min_date = None, input_max_date = None\n",
    "    '''\n",
    "    Creates a csv to specified file path\n",
    "    '''\n",
    "\n",
    "    tickers_sp100 = ref_data.get_sp100()\n",
    "    #ed.download_files_10k(â€˜AAPLâ€™, â€˜C:/10k_filings_rawâ€™)\n",
    "    ed.full_download([\"AAPL\", \"MSFT\", \"AMZN\", \"BRK-B\", \"GOOGL\", \"UNH\", \"GOOG\", \"JNJ\", \"XOM\", \"JPM\", \"NVDA\", \"PG\", \"V\", \"HD\", \"TSLA\"], r'C:\\10k_filings_raw', 'gregsmith@kubrickgroup.com', min_date = '2022-01-01', report = '10-K') #min_date = input_min_date, max_date = input_max_date,\n",
    "\n",
    "    ec.write_clean_html_text_files(r'C:\\10k_filings_raw', r'C:\\10k_filings_clean')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86ebcad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\ref_data.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(ticker_data, sort=False)\n",
      "c:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\ref_data.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(ticker_data, sort=False)\n",
      "c:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\ref_data.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(ticker_data, sort=False)\n",
      "c:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\ref_data.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(ticker_data, sort=False)\n",
      "c:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\ref_data.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(ticker_data, sort=False)\n",
      "c:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\ref_data.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(ticker_data, sort=False)\n",
      "c:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\ref_data.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(ticker_data, sort=False)\n",
      "c:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\ref_data.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(ticker_data, sort=False)\n",
      "c:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\ref_data.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(ticker_data, sort=False)\n",
      "c:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\ref_data.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(ticker_data, sort=False)\n",
      "c:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\ref_data.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(ticker_data, sort=False)\n",
      "c:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\ref_data.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(ticker_data, sort=False)\n",
      "c:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\ref_data.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(ticker_data, sort=False)\n",
      "c:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\ref_data.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(ticker_data, sort=False)\n",
      "c:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\ref_data.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(ticker_data, sort=False)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m     full_combined_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(full_stock_returns_daily_df, full_sentiment_factors_df, on \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mticker\u001b[39m\u001b[39m'\u001b[39m], how \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m     full_combined_df\u001b[39m.\u001b[39mto_csv(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mEdgar_EC\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mtest_output\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mfull_dataset.csv\u001b[39m\u001b[39m'\u001b[39m, index \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)              \u001b[39m# Will need to decide a better place for this\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m full_train_dataset()\n",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m, in \u001b[0;36mfull_train_dataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m esw\u001b[39m.\u001b[39mwrite_document_sentiments(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m10k_filings_clean\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mEdgar_EC\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mtest_output\u001b[39m\u001b[39m\\\u001b[39m\u001b[39msentiment_factors.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[39m# Load Data\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m stock_returns_daily_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mEdgar_EC\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mtest_output\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mstock_returns_daily.csv\u001b[39m\u001b[39m'\u001b[39m)                         \u001b[39m# Load in stock return data\u001b[39;00m\n\u001b[0;32m     11\u001b[0m sentiment_factors_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mEdgar_EC\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mtest_output\u001b[39m\u001b[39m\\\u001b[39m\u001b[39msentiment_factors.csv\u001b[39m\u001b[39m'\u001b[39m)                             \u001b[39m# Load in sentiment word count data\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#stock_returns_daily_df = pd.read_csv('C:/EDGAR/example_shares_output2.csv')   \u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#sentiment_factors_df = pd.read_csv('C:/EDGAR/example_sentiment_analysis.csv')  \u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[39m# Processing and Feature Engineering\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def full_train_dataset():\n",
    "   #df_returns = rf.get_yahoo_data(input_min_date, input_max_date, tickers_sp100, 'daily')\n",
    "    df_returns = ref_data.get_yahoo_data('2022-01-01', '2023-08-01', [\"AAPL\", \"MSFT\", \"AMZN\", \"BRK-B\", \"GOOGL\", \"UNH\", \"GOOG\", \"JNJ\", \"XOM\", \"JPM\", \"NVDA\", \"PG\", \"V\", \"HD\", \"TSLA\"]) # Need to decide dates as I have to pass a date here\n",
    "    df_returns.to_csv(r'C:\\Edgar_EC\\test_output\\stock_returns_daily.csv', index=False)\n",
    "    sentiment_dict = ref_data.get_sentiment_word_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e853fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    esw.write_document_sentiments(r'C:\\10k_filings_clean', r'C:\\Edgar_EC\\test_output\\sentiment_factors.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56a03d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\edgar_sentiment_analysis_prep.py:69: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  new_df['word_sum'] = new_df.sum(axis = 1)                                           # Calculate total number of categorised words from the report\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Modal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Modal'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m     full_combined_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(full_stock_returns_daily_df, full_sentiment_factors_df, on \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mticker\u001b[39m\u001b[39m'\u001b[39m], how \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m     full_combined_df\u001b[39m.\u001b[39mto_csv(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mEdgar_EC\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mtest_output\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mfull_dataset.csv\u001b[39m\u001b[39m'\u001b[39m, index \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)              \u001b[39m# Will need to decide a better place for this\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m full_train_dataset()\n",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m, in \u001b[0;36mfull_train_dataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39m#stock_returns_daily_df = pd.read_csv('C:/EDGAR/example_shares_output2.csv')   \u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m#sentiment_factors_df = pd.read_csv('C:/EDGAR/example_sentiment_analysis.csv')  \u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[39m# Processing and Feature Engineering\u001b[39;00m\n\u001b[0;32m     11\u001b[0m full_stock_returns_daily_df \u001b[39m=\u001b[39m esap\u001b[39m.\u001b[39mstock_returns_prep(stock_returns_daily_df)\n\u001b[1;32m---> 12\u001b[0m full_sentiment_factors_df \u001b[39m=\u001b[39m esap\u001b[39m.\u001b[39;49msentiment_factors_prep(sentiment_factors_df)\n\u001b[0;32m     14\u001b[0m \u001b[39m# Combine Datasets\u001b[39;00m\n\u001b[0;32m     15\u001b[0m full_combined_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(full_stock_returns_daily_df, full_sentiment_factors_df, on \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mticker\u001b[39m\u001b[39m'\u001b[39m], how \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\edgar_sentiment_analysis_prep.py:79\u001b[0m, in \u001b[0;36msentiment_factors_prep\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     77\u001b[0m new_df[\u001b[39m'\u001b[39m\u001b[39mperc_Superfluous\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: row[\u001b[39m'\u001b[39m\u001b[39mSuperfluous\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m/\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mword_sum\u001b[39m\u001b[39m'\u001b[39m], axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     78\u001b[0m new_df[\u001b[39m'\u001b[39m\u001b[39mperc_Interesting\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: row[\u001b[39m'\u001b[39m\u001b[39mInteresting\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m/\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mword_sum\u001b[39m\u001b[39m'\u001b[39m], axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m---> 79\u001b[0m new_df[\u001b[39m'\u001b[39m\u001b[39mperc_Modal\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m row: row[\u001b[39m'\u001b[39;49m\u001b[39mModal\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m/\u001b[39;49m row[\u001b[39m'\u001b[39;49m\u001b[39mword_sum\u001b[39;49m\u001b[39m'\u001b[39;49m], axis \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[0;32m     80\u001b[0m \u001b[39m#Sentiment Scores\u001b[39;00m\n\u001b[0;32m     81\u001b[0m new_df[\u001b[39m'\u001b[39m\u001b[39msentiment_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: \u001b[39mround\u001b[39m((row[\u001b[39m'\u001b[39m\u001b[39mPositive\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mNegative\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m/\u001b[39m (row[\u001b[39m'\u001b[39m\u001b[39mPositive\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mNegative\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39m2\u001b[39m), axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)  \n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    893\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Edgar_EC\\edgar_ec_2\\edgar_ec\\edgar_sentiment_analysis_prep.py:79\u001b[0m, in \u001b[0;36msentiment_factors_prep.<locals>.<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     77\u001b[0m new_df[\u001b[39m'\u001b[39m\u001b[39mperc_Superfluous\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: row[\u001b[39m'\u001b[39m\u001b[39mSuperfluous\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m/\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mword_sum\u001b[39m\u001b[39m'\u001b[39m], axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     78\u001b[0m new_df[\u001b[39m'\u001b[39m\u001b[39mperc_Interesting\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: row[\u001b[39m'\u001b[39m\u001b[39mInteresting\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m/\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mword_sum\u001b[39m\u001b[39m'\u001b[39m], axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m---> 79\u001b[0m new_df[\u001b[39m'\u001b[39m\u001b[39mperc_Modal\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: row[\u001b[39m'\u001b[39;49m\u001b[39mModal\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m/\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mword_sum\u001b[39m\u001b[39m'\u001b[39m], axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[39m#Sentiment Scores\u001b[39;00m\n\u001b[0;32m     81\u001b[0m new_df[\u001b[39m'\u001b[39m\u001b[39msentiment_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: \u001b[39mround\u001b[39m((row[\u001b[39m'\u001b[39m\u001b[39mPositive\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mNegative\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m/\u001b[39m (row[\u001b[39m'\u001b[39m\u001b[39mPositive\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mNegative\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39m2\u001b[39m), axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)  \n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Modal'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def full_train_dataset():\n",
    "    # Load Data\n",
    "    stock_returns_daily_df = pd.read_csv(r'C:\\Edgar_EC\\test_output\\stock_returns_daily.csv')                         # Load in stock return data\n",
    "    sentiment_factors_df = pd.read_csv(r'C:\\Edgar_EC\\test_output\\sentiment_factors.csv')                             # Load in sentiment word count data\n",
    "    #stock_returns_daily_df = pd.read_csv('C:/EDGAR/example_shares_output2.csv')   \n",
    "    #sentiment_factors_df = pd.read_csv('C:/EDGAR/example_sentiment_analysis.csv')  \n",
    "    \n",
    "    # Processing and Feature Engineering\n",
    "    full_stock_returns_daily_df = esap.stock_returns_prep(stock_returns_daily_df)\n",
    "    full_sentiment_factors_df = esap.sentiment_factors_prep(sentiment_factors_df)\n",
    "    \n",
    "    # Combine Datasets\n",
    "    full_combined_df = pd.merge(full_stock_returns_daily_df, full_sentiment_factors_df, on = ['Date', 'ticker'], how = 'left')\n",
    "\n",
    "    full_combined_df.to_csv(r'C:\\Edgar_EC\\test_output\\full_dataset.csv', index = False)              # Will need to decide a better place for this\n",
    "\n",
    "full_train_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
